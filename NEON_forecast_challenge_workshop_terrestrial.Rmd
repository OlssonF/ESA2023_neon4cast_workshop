---
title: "NEON forecast challenge - terrestrial daily"
author: Freya Olsson
output:
  md_document: 
    variant: markdown_github
    number_sections: true
    toc: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(dplyr.summarise.inform = FALSE)
```

# This R markdown document
This document present workshop materials presented at the ESA 2023 workshop "Can You Predict the Future? Introducing the NEON Ecological Forecasting Challenge."

To complete the workshop via this markdown document the following packages will need to be installed:

* `remotes`
* `fpp3`
* `tsibble`
* `tidyverse`
* `lubridate`
* `neon4cast` (from github)

The following code chunk should be run to install packages.

```{r eval = F}
install.packages('remotes')
install.packages('fpp3') # package for applying simple forecasting methods
install.packages('tsibble') # package for dealing with time series data sets and tsibble objects
install.packages('tidyverse') # collection of R packages for data manipulation, analysis, and visualisation
install.packages('lubridate') # working with dates and times
remotes::install_github('eco4cast/neon4cast') # package from NEON4cast challenge organisers to assist with forecast building and submission

```

Additionally, R version 4.2 is required to run the `neon4cast` package. It's also worth checking your Rtools is up to date and compatible with R 4.2, see (https://cran.r-project.org/bin/windows/Rtools/rtools42/rtools.html). 

```{r}
version$version.string


library(tidyverse)
library(lubridate)
```

If you do not wish to run the code yourself you can follow along via the rendered markdown document (NEON_forecast_challenge_workshop_terrestrial.md).

# Introduction to NEON forecast challenge

The EFI RCN NEON Forecast Challenge asks the scientific community to produce ecological forecasts of future conditions at NEON sites by leveraging NEON's open data products. The Challenge is split into five themes that span aquatic and terrestrial systems, and population, community, and ecosystem processes across a broad range of ecoregions. We are excited to use this Challenge to learn more about the predictability of ecological processes by forecasting NEON data before it is collected.  
  
Which modeling frameworks, mechanistic processes, and statistical approaches best capture community, population, and ecosystem dynamics? These questions are answerable by a community generating a diverse array of forecasts. The Challenge is open to any individual or team from anywhere around the world that wants to submit forecasts. Sign up [here.](https://projects.ecoforecast.org/neon4cast-docs/Participation.html). 

## Terrestrial challenge

What: Net ecosystem exchange of CO2 and evapotranspiration in terrestrial ecosystems. Forecasts can be submitted at a daily or 30 minute timestep.

Where: 47 NEON sites across the U.S. and Puerto Rico.

When: Daily forecasts for at least 30-days in the future. New forecast submissions, that use newly collected data, are accepted daily. The only requirement is that submissions are predictions of the future at the time the forecast is submitted.

Today we will focus on forecasts of net ecosystem exchange of CO2 (NEE) at a daily timestep in  g C m-2 day-1. Negative values correspond to an ecosystem absorbing CO2 from the atmosphere, positive values correspond to an ecosystem emitting CO2 to the atmosphere. Find more information about the terrestrial challenge [here](https://projects.ecoforecast.org/neon4cast-docs/Terrestrial.html).

## Submission requirements

For the Challenge, forecasts must include quantified uncertainty. The file can represent uncertainty using an ensemble forecast (multiple realizations of future conditions) or a distribution forecast (with mean and standard deviation), specified in the family and parameter columns of the forecast file. 

For an ensemble forecast, the `family` column uses the word `ensemble` to designate that it is a ensemble forecast and the parameter column is the ensemble member number (1, 2, 3 …).  For a distribution forecast, the `family` column uses the word `normal` to designate a normal distribution and the parameter column must have the words mu and sigma for each forecasted variable, site_id, and datetime. For forecasts that don't have a normal distribution we recommend using the ensemble format and sampling from your non-normal distribution to generate a set of ensemble members that represents your distribution. I will go through examples of both `ensemble` and `normal` forecasts as examples. 

The full list of required columns and format can be found in the [Challenge documentation](https://projects.ecoforecast.org/neon4cast-docs/Submission-Instructions.html).

# The forecasting workflow
## Read in the data

We start forecasting by first looking at the historic data - called the 'targets'. These data are available with a 5 day delay (latency). Here is how you read in the data from the targets file available from the EFI server. 

```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
#read in the targets data
targets <- readr::read_csv("https://data.ecoforecast.org/neon4cast-targets/terrestrial_daily/terrestrial_daily-targets.csv.gz", guess_max = 1e6) |> 
  na.omit()
```

Information on the NEON sites can be found in the `NEON_Field_Site_Metadata_20220412.csv` file on GitHub. It can be filtered to only include terrestrial sites. This table has information about the field sites, including location, ecoregion, information vegetation type (`phenocam_vegetation`), canopy height, and soil type. 
 
```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
# read in the sites data
site_data <- readr::read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv") |> 
  dplyr::filter(terrestrial == 1)
```

Let's take a look at the targets data!
```{r eval = T, echo = F}
targets[1000:1010,]

```

The columns of the targets file show the time step (daily for the terrestrial daily challenge), the 4 character site code (`site_id`), the variable being measured, and the mean daily observation. We will filter the targets to look at only the NEE (`nee`). 

```{r}
variable_interest <- 'nee'
targets <- targets |> 
  dplyr::filter(variable == variable_interest)
```

## Visualise the data
```{r targets, eval = T, echo = F, warning=FALSE, fig.dim=c(10,10), fig.cap=c('Figure: Targets data at terrestrial sites provided by EFI for the NEON forecasting challgenge')}
sites1 <- site_data[1:12,]
sites2 <- site_data[13:24,]
sites3 <- site_data[25:36,]
sites4 <- site_data[37:47,]
  
targets %>%
  filter(site_id %in% sites1$field_site_id) |> 
  ggplot(aes(x = datetime, y = observation)) +
  geom_point() +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_wrap(~site_id, scales = 'free_y') +
  labs(y = variable_interest)

targets %>%
  filter(site_id %in% sites2$field_site_id) |> 
  ggplot(aes(x = datetime, y = observation)) +
  geom_point() +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_wrap(~site_id, scales = 'free_y') +
  labs(y = variable_interest)

targets %>%
  filter(site_id %in% sites3$field_site_id) |> 
  ggplot(aes(x = datetime, y = observation)) +
  geom_point() +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_wrap(~site_id, scales = 'free_y') +
  labs(y = variable_interest)

targets %>%
  filter(site_id %in% sites4$field_site_id) |> 
  ggplot(aes(x = datetime, y = observation)) +
  geom_point() +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_wrap(~site_id, scales = 'free_y') +
  labs(y = variable_interest)

```

We can think about what type of models might be useful to predict these variables at these sites. Below are descriptions of three simple models which have been constructed to get you started forecasting:

* We could use information about recent conditions to predict the future. What is happening today is usually a good predictor of what will happen tomorrow.
* And we could think about what the historic data tells us about this time of year. Is this time of year likely to be similar the same period last year? 
* We could also look at the variable's relationship(s) with other variables. Could we use existing forecasts about the weather to generate forecasts about terrestrial fluxes?

# Introducing co-variates

One important step to overcome when thinking about generating forecasts is how to include co-variates in the model. A forecast of NEE, for example, may be benefit from information about past and future weather. The `neon4cast` challenge package includes functions for downloading past and future NOAA weather forecasts for all of the NEON sites. The 3 types of data are as follows:

* stage_1: raw forecasts - 31 member ensemble forecasts at 3 hr intervals for the first 10 days, and 6 hr intervals for up to 35 days at the NEON sites.
* stage_2: a processed version of Stage 1 in which fluxes are standardized to per second rates, fluxes and states are interpolated to 1 hour intervals and variables are renamed to match conventions. We recommend this for obtaining future weather by using `neon4cast::noaa_stage2()`. Future weather forecasts include a 30-member ensemble of equally likely future weather conditions.
* stage_3: can be viewed as the "historical" weather and is combination of day 1 weather forecasts (i.e., when the forecasts are most accurate). You can download this “stacked” NOAA product using `neon4cast::noaa_stage3()`.

These functions create a connection to the dataset hosted on the eco4cast server. To download the data you have to tell the function to `collect()` it. These data set can be subsetted and filtered using `dplyr` functions prior to download to limit the memory usage.

You can read more about the NOAA forecasts available for the NEON sites [here:](https://projects.ecoforecast.org/neon4cast-docs/Shared-Forecast-Drivers.html)

## Download co-variates
### Download historic data

We will generate a `nee` forecast using `air_temperature` and `solar_radiation` as a co-variates. As an example of the workflow we will work with 1 site - HARV (Harvard deciduous forest).
```{r HARV}
example_site <- 'HARV'

targets |> 
  filter(site_id  == example_site) |> 
  ggplot(aes(x=datetime, y= observation)) +
  geom_point()
```



```{r, message=FALSE}
example_site <- 'HARV'

# past stacked weather
df_past <- neon4cast::noaa_stage3()

variables <- c("air_temperature", "surface_downwelling_shortwave_flux_in_air")
#Other variable names can be found at https://projects.ecoforecast.org/neon4cast-docs/Shared-Forecast-Drivers.html#stage-2

noaa_past_example <- df_past |> 
  dplyr::filter(site_id %in% example_site,
                datetime >= ymd('2017-01-01'),
                variable %in% variables) |> 
  dplyr::collect()

noaa_past_example[1:10,]
```

This is a stacked ensemble forecast of the one day ahead hourly forecasts. To get an estimate of the historic conditions we can take a mean of these ensembles. We will also need to convert the temperatures to Celsius from Kelvin.

```{r}
# aggregate the past to mean values
noaa_past_mean_example <- noaa_past_example |> 
  mutate(datetime = as_date(datetime)) |> 
  group_by(datetime, site_id, variable) |> 
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") |> 
  pivot_wider(names_from = variable, values_from = prediction) |> 
  # convert air temp to C
  rename(shortwave = surface_downwelling_shortwave_flux_in_air) |> 
  mutate(air_temperature = air_temperature - 273.15)


head(noaa_past_mean_example)
```

We can then look at the future weather forecasts in the same way but using the `noaa_stage2()`. The forecast becomes available from NOAA at 5am UTC the following day, so we take the air temperature and shortwave forecast from yesterday (`noaa_date`) to make the NEE forecasts. Then we can use the weather forecast ensembles to produce uncertainty in the NEE forecast by forecasting multiple (31) future conditions. 

### Download future weather forecasts

```{r, message=FALSE}
# New forecast only available at 5am UTC the next day

forecast_date <- Sys.Date() 
noaa_date <- forecast_date - days(1)

df_future <- neon4cast::noaa_stage2()

variables <- c("air_temperature", "surface_downwelling_shortwave_flux_in_air")

noaa_future_example <- df_future |> 
  dplyr::filter(reference_datetime == noaa_date,
                datetime >= forecast_date,
                site_id %in% example_site,
                variable %in% variables,
                # Only need a 30 day horizon (31 *24 , today + 30 days)
                horizon < 744,
                # ensemble member 31 only goes to 16 days
                parameter < 31) |> 
  dplyr::collect()
noaa_future_example
```

These forecasts are hourly and we are interested in using daily mean air temperature and shortwave for NEE forecast generation.

```{r warning=F}
noaa_future_daily_example <- noaa_future_example |> 
  mutate(datetime = as_date(datetime)) |> 
  # mean daily forecasts at each site per ensemble
  group_by(datetime, site_id, parameter, variable) |> 
  summarize(prediction = mean(prediction)) |>
  pivot_wider(names_from = variable, values_from = prediction) |>
  # convert to Celsius
  mutate(air_temperature = air_temperature - 273.15) |> 
  rename(shortwave = surface_downwelling_shortwave_flux_in_air) |> 
  select(datetime, site_id, air_temperature, shortwave, parameter)

noaa_future_daily_example
```

Now we have a timeseries of historic data and a 30 member ensemble forecast of future air temperatures and shortwave for one site. 

```{r NOAA-HARV, echo = F, fig.cap = c('Figure: historic and future NOAA air temeprature forecasts for 1 NEON site', 'Figure: historic and future NOAA shortwave forecasts for 1 NEON site ')}
noaa_future_daily_example |> 
  filter(site_id == 'HARV') |> 
  ggplot(aes(x=datetime, y=air_temperature)) +
  geom_line(aes(group = parameter), alpha = 0.4)+
  geom_line(data = subset(noaa_past_mean_example, site_id == 'HARV'), colour = 'darkblue') +
  coord_cartesian(xlim = c(noaa_date - days(60),
                           noaa_date + days(32)))+
  facet_wrap(~site_id, scales = 'free')

noaa_future_daily_example |> 
  filter(site_id == 'HARV') |> 
  ggplot(aes(x=datetime, y=shortwave)) +
  geom_line(aes(group = parameter), alpha = 0.4)+
  geom_line(data = subset(noaa_past_mean_example, site_id == 'HARV'), colour = 'darkblue') +
  coord_cartesian(xlim = c(noaa_date - days(60),
                           noaa_date + days(32)))+
  facet_wrap(~site_id, scales = 'free')
```

# Model 1: Linear model with covariates

We will fit a simple linear model between historic air temperature, shortwave radiation and the net ecosystem exchange targets data. Using this model we can then use our future estimates of air temperature (all 30 ensembles) to estimate nee. The ensemble weather forecast will therefore propagate uncertainty into the nee forecast and give an estimate of driving data uncertainty. 

We will start by joining the historic weather data with the targets to aid in fitting the linear model.

```{r}
targets_lm_example <- targets |> 
  filter(site_id %in% example_site) |> 
  pivot_wider(names_from = 'variable', 
              values_from = 'observation') |> 
  left_join(noaa_past_mean_example, 
            by = c("datetime","site_id"))

tail(targets_lm_example)
```


To fit the linear model we use the base R `lm()` but there are also methods to fit linear (and non-linear) models in the `fable::` package. You can explore the [documentation](https://otexts.com/fpp3/regression.html) for more information on the `fable::TSLM()` function. We can fit a separate linear model for each site. For example, at HARV forest (HARV), this would look like:

```{r, eval = T}

#Fit linear model based on past data: water temperature = m * air temperature + b
fit <- lm(targets_lm_example$nee ~ targets_lm_example$air_temperature + targets_lm_example$shortwave)
    
# use linear regression to forecast water temperature for each ensemble member
forecasted_nee <- fit$coefficients[1] + 
  (fit$coefficients[2] * noaa_future_daily_example$air_temperature) + 
  (fit$coefficients[3] * noaa_future_daily_example$shortwave)

```

```{r example-forecast}
  # put all the relevent information into a tibble that we can bind together
  NEE <- data.frame(datetime = noaa_future_daily_example$datetime,
                        site_id = "HARV",
                        parameter = noaa_future_daily_example$parameter,
                        prediction = forecasted_nee,
                        variable = "nee")
  
  ggplot(NEE, aes(x = datetime, y = prediction, group = parameter)) +
    geom_line()
  
  
  
  # Some edits would be needed to submit to the challenge... see commented code
  
  #   my_model_id <- 'nee_test'
  # 
  # NEE_forecast_EFI <- NEE %>%
  #   mutate(model_id = my_model_id,
  #          reference_datetime = as_date(min(datetime)) - days(1),
  #          family = 'ensemble',
  #          parameter = as.character(parameter)) %>%
  # select(model_id, datetime, reference_datetime, site_id, family, parameter, variable, prediction)
```

A forecast!!

We can loop through this workflow for each site to create a site-wise forecast of NEE based on a linear model and each forecasted air temperature and shortwave. We can run this forecast for each site and then bind them together to submit as one forecast. 
 
1. Download historic NOAA data
2. Download future NOAA forecast
3. Fit the model
4. Forecast!
5. Bind this all together...

Note: This loop takes a while to execute so start it running as soon as possible...
```{r}
# Create the connections to data products
df_past <- neon4cast::noaa_stage3()

forecast_date <- Sys.Date() 
noaa_date <- forecast_date - days(1)
df_future <- neon4cast::noaa_stage2()

# specify the covariates
variables <- c("air_temperature", "surface_downwelling_shortwave_flux_in_air")

# create some empty objects to assign things to
lm_forecast <- NULL
model_fit <- NULL

loop_sites <- 1:5 #1:length(site_data$field_site_id)

## Stash NOAA locally. This will speed up the access to NOAA by writing a local copy that we query
df_past |> 
    dplyr::filter(datetime >= ymd('2017-01-01'),
                  variable %in% variables) |> 
    arrow::write_dataset("noaa_past", partitioning="site_id")
    
df_future |> 
    dplyr::filter(reference_datetime == noaa_date,
                  datetime >= forecast_date,
                  variable %in% variables,
                  horizon < 744,
                  parameter < 31) |> 
    arrow::write_dataset("noaa_future", partitioning="site_id")


for(i in 1:length(site_data$field_site_id)) {  
  
  site <- site_data$field_site_id[i]
  
  # 1. Get historic NOAA data
  noaa_past <- arrow::open_dataset("noaa_past") |> 
    dplyr::filter(site_id %in% site,
                  datetime >= ymd('2017-01-01'),
                  variable %in% variables) |> 
    dplyr::collect()
  
  # calculate a daily mean to fit the model
  noaa_past_daily <- noaa_past |> 
    mutate(datetime = as_date(datetime)) |> 
    group_by(datetime, site_id, variable) |> 
    summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") |> 
    pivot_wider(names_from = variable, values_from = prediction) |> 
    # convert air temp to C
    rename(shortwave = surface_downwelling_shortwave_flux_in_air) |> 
    mutate(air_temperature = air_temperature - 273.15)
  
  # message('Stage 3 for ', site)

  
  #2. Get future NOAA data
  # Download the stage2 data
  noaa_future <- arrow::open_dataset("noaa_future") |> 
    dplyr::filter(reference_datetime == noaa_date,
                  datetime >= forecast_date,
                  site_id %in% site,
                  variable %in% variables,
                  horizon < 744,
                  parameter < 31) |> 
    dplyr::collect()
  
  # generate a mean daily forecast to use in the forecast
  noaa_future_daily <- noaa_future |> 
    mutate(datetime = as_date(datetime)) |> 
    # mean daily forecasts at each site per ensemble
    group_by(datetime, site_id, parameter, variable) |> 
    summarize(prediction = mean(prediction)) |>
    pivot_wider(names_from = variable, values_from = prediction) |>
    # convert to Celsius
    mutate(air_temperature = air_temperature - 273.15) |> 
    rename(shortwave = surface_downwelling_shortwave_flux_in_air) |> 
    select(datetime, site_id, air_temperature, shortwave, parameter)
  
   # message('Stage 2 for ', site)
  
  #3. Fit the model
    # targets data reformatted to aid model fitting

   targets_lm <- targets |> 
     filter(site_id == site) |> 
     pivot_wider(names_from = 'variable', values_from = 'observation') |> 
     left_join(noaa_past_daily, 
            by = c("datetime","site_id"))
  
  #Fit linear model based on past data
  fit <- lm(targets_lm$nee ~ targets_lm$air_temperature + targets_lm$shortwave)
    
  # use linear regression to forecast water temperature for each ensemble member
  forecasted_nee <- fit$coefficients[1] + 
    (fit$coefficients[2] * noaa_future_daily$air_temperature) + 
    (fit$coefficients[3] * noaa_future_daily$shortwave)
    
  # put all the relevant information into a tibble that we can bind together
  NEE <- tibble(datetime = noaa_future_daily$datetime,
                        site_id = site,
                        parameter = noaa_future_daily$parameter,
                        prediction = forecasted_nee,
                        variable = "nee")
  
  lm_forecast <- dplyr::bind_rows(lm_forecast, NEE)
  message(site, ' NEE forecast run')
  
  # extract the model fit
  # you can comment/uncomment this out to extract the R-squared from the model summary
  
  # model_fit <- dplyr::bind_rows(model_fit, data.frame(site_id = site,
  #                                                     r_squared = summary(fit)$r.squared))
  
  
}
```

We now have 30 possible forecasts of NEE at each site and each day. On this plot each line represents one of the possible forecasts and the range of forecasted NEE is a simple quantification of the uncertainty in our forecast.

Looking back at the forecasts we produced:

```{r nee-forecasts, echo = F, warning = F}
lm_forecast %>% 
  filter(site_id %in% site_data$field_site_id[1:9]) |> 
  ggplot(aes(x=datetime, y=prediction, group = parameter)) + 
  geom_point(data = subset(targets, site_id %in% site_data$field_site_id[loop_sites]),
             aes(x=datetime, y=observation, group = 'obs'), colour = 'darkblue') +
  geom_line(alpha = 0.5, aes(colour = 'ensemble member (parameter)')) + 
  scale_x_date(expand = c(0,0), date_labels = "%d %b") +
  labs(y = 'value') +
  facet_wrap(~site_id, nrow = 3, scales = 'free') +
  geom_vline(aes(linetype = 'reference_datetime', xintercept = Sys.Date()), colour = 'blue', size = 1.5) +
  labs(subtitle = 'variable = nee', caption = 'prediction') + 
  annotate("text", x = Sys.Date() - days(15), y = 2, label = "past")  +
  annotate("text", x = Sys.Date() + days(15), y = 2, label = "future")  +
  theme_bw() +
  coord_cartesian(xlim = c(min(lm_forecast$datetime) - 60,
                           Sys.Date() + 30)) +
  scale_linetype_manual(values = 'dashed', name = '') +
  scale_colour_manual(values = 'darkgrey', name = '') +
  theme(legend.position = 'bottom')
```

## Convert to EFI standard for submission
For an ensemble forecast the documentation specifies the following columns:

* `datetime`: forecast timestamp for each time step
* `reference_datetime`: The start of the forecast; this should be 0 times steps in the future. This should only be one value of reference_datetime in the file
* `site_id`: NEON code for site
* `family`: name of probability distribution that is described by the parameter values in the parameter column; only `normal` or `ensemble` are currently allowed.
* `parameter`: integer value for forecast replicate (from the `.rep` in fable output);
* `variable`: standardized variable name from the theme 
* `prediction`: forecasted value 
* `model_id`: model name (no spaces)

We need to make sure the dataframe is in the correct format and then we can submit this to the challenge as well! This is an ensemble forecast (specified in the `family` column). 

```{r}
# Remember to change the model_id when you make changes to the model structure!
my_model_id <- 'ESA_example'

lm_forecast_EFI <- lm_forecast %>%
  mutate(model_id = my_model_id,
         reference_datetime = as_date(min(datetime)) - days(1),
         family = 'ensemble',
         parameter = as.character(parameter)) %>%
  select(model_id, datetime, reference_datetime, site_id, family, parameter, variable, prediction)
```

## Submit forecast
Files need to be in the correct format for submission. The forecast organizers have created tools to help aid in the submission process. These tools can be downloaded from Github using `remotes::install_github(eco4cast/neon4cast)`.
These include functions for submitting, scoring and reading forecasts:

* `submit()` - submit the forecast file to the neon4cast server where it will be scored
* `forecast_output_validator()` - will check the file is in the correct format to be submitted
* `check_submission()` - check that your submission has been uploaded to the server

The file name needs to be in the format theme-reference_datetime-model_id
```{r eval = T}
# Start by writing the forecast to file
theme <- 'terrestrial_daily'
date <- lm_forecast_EFI$reference_datetime[1]
forecast_name_1 <- paste0(lm_forecast_EFI$model_id[1], ".csv")
forecast_file_1 <- paste(theme, date, forecast_name_1, sep = '-')
forecast_file_1

write_csv(lm_forecast_EFI, forecast_file_1)

neon4cast::forecast_output_validator(forecast_file_1)

```

```{r eval = FALSE}
# can uses the neon4cast::forecast_output_validator() to check the forecast is in the right format
neon4cast::submit(forecast_file = forecast_file_1,
                  ask = TRUE) # if ask = T (default), it will produce a pop-up box asking if you want to submit
```

Is the linear model a reasonable relationship between NEE and air temperature and solar radiation? Would some non-linear relationship be better? What about using maximum shortwave to predict NEE? Or including additional parameters? 

## TASKS
Possible modifications to Model 1 - simple linear model: 

* Include additional NOAA co-variates in the linear model (remember to 'collect' and subset the right data from NOAA)
* Specify a non-linear relationship
* Try forecasting another variable (latent heat flux of evapotranspiration)
* Include a lag in the predictors
* Include additional sources of uncertainty - what is the error of the residuals and what does this indicate about the uncertainty in the model.

Remember to change the `model_id` so we can differentiate different forecasts!

## Register your participation
It's really important that once you start submitting forecasts to the Challenge that you register your participation. We ask that you complete this [form](https://nd.qualtrics.com/jfe/form/SV_9MJ29y2xNrBOjqZ) which asks you some simple questions about your forecast and team. This is crucial for a couple of reasons:

1. We can keep track different forecast submissions during the scoring process to see which forecast is performing the best. Your `model_id` will be used to track the submissions so any new forecast model requires a new `model_id`.
2. The form gives consent for submissions to be included in Challenge-wide syntheses being carried out by the Challenge organisers. Partipants in the Challenge will be invited to join the synthesis projects on an opt-in basis. 


## Automate your forecasts!
One of the most exciting parts of near-term ecological forecasting is the iterative nature of it. Submitting a brand new forecast everyday with updated models etc. will test how well your model does over different days. You can also continue to tune parameters, update initial conditions, or modify the model as new data are collected. 

## See how your forecasts perform

During this workshop, we have gone through a simple forecast submission workflow. This submits a standardised format forecast to an AWS (Amazon Web Services) bucket which will automatically undergo 'scoring', comparing your prediction (and the associated uncertainty) with the observations collected by NEON to produce score metrics. These scores tell us how well each model was able to reproduce the observations, with lower scores indicating higher performance (and lower error). See [here]() for information about how the scores are calculated. 

We don't have time to do this in this workshop but if you are interested in knowing more about your forecast's performance, see the [dashboard]() or [this tutorial](https://github.com/OlssonF/NEON-forecast-challenge-workshop/tree/main/Analyse_scores) to learn about accessing, visualising, and analysing forecast performance.